Here‚Äôs a **detailed project requirement document** for converting your Rethink ‚Üí Supabase pipeline into a Cloud Run-hosted webhook, callable via Make.com
---

## üìÑ Project Requirements Document

**Project Name:**
Daily Rethink ‚Üí Supabase Data Sync via Google Cloud Run

**Prepared for:**
AllCheer Tools

**Date:**
June 21, 2025

---

### ‚úÖ Project Objective

To automate the daily download of appointment data from the Rethink Behavioral Health dashboard and ingest it into a Supabase PostgreSQL table (`rethinkDump`). The goal is to host this logic as a single HTTP endpoint on **Google Cloud** that can be triggered daily via **Make.com**.

---

### üîß Functional Requirements

#### 1. **Python Script Unification**

* ‚úÖ **COMPLETED** - Combined download and ingestion logic into a single unified script.
* The unified script should:

  1. ‚úÖ Authenticate and download the latest Excel data from Rethink (in-memory processing).
  2. ‚úÖ Truncate and reset the Supabase table (`rethinkDump`).
  3. ‚úÖ Map and insert all Excel rows into Supabase using optimized batch processing.
  4. ‚úÖ Memory-efficient processing without temporary file storage.

#### 2. **API Wrapper**

* ‚úÖ **COMPLETED** - Wrapped the unified script in a **FastAPI** app.
* ‚úÖ **COMPLETED** - Created multiple endpoints:

  * `GET/POST /run` ‚Üí Executes the download + ingestion logic.
  * `GET /health` ‚Üí Health check endpoint.
  * `GET /` ‚Üí Service information.
  * `GET /docs` ‚Üí API documentation.
* ‚úÖ **COMPLETED** - Enhanced JSON status report with timing information:

  ```json
  {
    "status": "success",
    "rows_inserted": 3894,
    "errors": 0,
    "total_rows": 3894,
    "timestamp": "2025-06-21T17:32:20.577612",
    "duration_seconds": 23.7,
    "message": "Sync completed successfully"
  }
  ```

#### 3. **Cloud Hosting with Google Cloud Run**

* Dockerize the FastAPI app.
* Deploy the container to **Google Cloud Run**:

  * Runtime: Python 3.11
  * Trigger: HTTP (allow unauthenticated access unless security is required)
  * Timeout: 300 seconds
  * Region: `us-central1` or preferred

#### 4. **Triggering Options**

Provide support to trigger the webhook:

##### a. Make.com (Webhook HTTP Request Module)

* Scenario: Custom automation using Make
* Trigger: HTTP GET to Cloud Run endpoint
* Optional: Add Make webhook key as a query param for basic security

#### 5. **Environment Variables (via .env or Secret Manager)**

The following variables must be securely loaded:

* `RTHINK_USER`
* `RTHINK_PASS`
* `SUPABASE_DB_URL`

---

### üì¶ Non-Functional Requirements

| Requirement    | Description                                                                          |
| -------------- | ------------------------------------------------------------------------------------ |
| Security       | No PII should be printed in logs. Optionally restrict access via Auth Header or OIDC |
| Logging        | Include `print()` logs or structured logging for cloud monitoring                    |
| Error Handling | Must not partially truncate/upload; fail gracefully if download fails                |
| Scalability    | Should handle up to 5,000 rows per execution                                         |
| Reliability    | Retry logic not required        |

---

### üìÅ Project Structure

```
project-root/
‚îÇ
‚îú‚îÄ‚îÄ main.py             # FastAPI entrypoint
‚îú‚îÄ‚îÄ rethink_sync.py     # Contains all core logic (download + upload)
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ .env                # Local-only (not committed)
```

---

### üê≥ Dockerfile Requirements

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY . /app

RUN pip install -r requirements.txt

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]
```

---

### üì° API Endpoint Summary

| Endpoint | Method | Description                           | Security                                  |
| -------- | ------ | ------------------------------------- | ----------------------------------------- |
| `/run`   | GET    | Run full sync job (download + upload) | Optional query key or Cloud Scheduler IAM |

---

### üöÄ Deployment Steps

1. **Build Docker image:**

   ```bash
   gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/rethink-sync
   ```

2. **Deploy to Cloud Run:**

   ```bash
   gcloud run deploy rethink-sync \
     --image gcr.io/YOUR_PROJECT_ID/rethink-sync \
     --platform managed \
     --region us-central1 \
     --allow-unauthenticated
   ```

3. **Set up Cloud Scheduler (optional):**

   ```bash
   gcloud scheduler jobs create http rethink-sync-daily \
     --schedule "0 3 * * *" \
     --uri https://rethink-sync-xxxx.a.run.app/run \
     --http-method GET
   ```

---

### ‚úÖ Acceptance Criteria

| Criterion                            | Description                                                 |
| ------------------------------------ | ----------------------------------------------------------- |
| API responds with success            | `/run` endpoint returns JSON with rows inserted             |
| Excel is downloaded correctly        | File saved in memory or tempdir and parsed                  |
| Supabase table is truncated          | Old data is deleted, IDs are reset                          |
| Data is inserted without error       | All rows accounted for (log errors if any)                  |
| File is deleted after upload         | Prevents duplication on future runs                         |
| Endpoint can be triggered externally | Works from Make.com or Cloud Scheduler without auth headers |

---

Would you like me to prepare the actual `main.py`, `Dockerfile`, and `requirements.txt` to match this plan?
